{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('crx.data', delimiter=\",\", header=None, na_values=[\"?\"], names=['0', 'First', 'Second', '3','4', '5', '6', 'Seventh','8', '9', 'Tenth', '11','12', 'Thirteen', 'Fourteen', 'Approval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['index'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Seventh</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Tenth</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>Thirteen</th>\n",
       "      <th>Fourteen</th>\n",
       "      <th>Approval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  First  Second  3  4  5  6  Seventh  8  9  Tenth 11 12  Thirteen  \\\n",
       "0  b  30.83   0.000  u  g  w  v     1.25  t  t      1  f  g     202.0   \n",
       "1  a  58.67   4.460  u  g  q  h     3.04  t  t      6  f  g      43.0   \n",
       "2  a  24.50   0.500  u  g  q  h     1.50  t  f      0  f  g     280.0   \n",
       "3  b  27.83   1.540  u  g  w  v     3.75  t  t      5  t  g     100.0   \n",
       "4  b  20.17   5.625  u  g  w  v     1.71  t  f      0  f  s     120.0   \n",
       "\n",
       "   Fourteen Approval  \n",
       "0         0        +  \n",
       "1       560        +  \n",
       "2       824        +  \n",
       "3         3        +  \n",
       "4         0        +  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 653 entries, 0 to 652\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   0         653 non-null    object \n",
      " 1   First     653 non-null    float64\n",
      " 2   Second    653 non-null    float64\n",
      " 3   3         653 non-null    object \n",
      " 4   4         653 non-null    object \n",
      " 5   5         653 non-null    object \n",
      " 6   6         653 non-null    object \n",
      " 7   Seventh   653 non-null    float64\n",
      " 8   8         653 non-null    object \n",
      " 9   9         653 non-null    object \n",
      " 10  Tenth     653 non-null    int64  \n",
      " 11  11        653 non-null    object \n",
      " 12  12        653 non-null    object \n",
      " 13  Thirteen  653 non-null    float64\n",
      " 14  Fourteen  653 non-null    int64  \n",
      " 15  Approval  653 non-null    object \n",
      "dtypes: float64(4), int64(2), object(10)\n",
      "memory usage: 81.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['0', '3', '4', '5', '6', '8', '9', '11', '12']\n",
    "def encoding(df):\n",
    "    for col in cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoding(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.Approval = encoded_data.Approval.replace({'+':1, '-':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 653 entries, 0 to 652\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   0         653 non-null    int32  \n",
      " 1   First     653 non-null    float64\n",
      " 2   Second    653 non-null    float64\n",
      " 3   3         653 non-null    int32  \n",
      " 4   4         653 non-null    int32  \n",
      " 5   5         653 non-null    int32  \n",
      " 6   6         653 non-null    int32  \n",
      " 7   Seventh   653 non-null    float64\n",
      " 8   8         653 non-null    int32  \n",
      " 9   9         653 non-null    int32  \n",
      " 10  Tenth     653 non-null    int64  \n",
      " 11  11        653 non-null    int32  \n",
      " 12  12        653 non-null    int32  \n",
      " 13  Thirteen  653 non-null    float64\n",
      " 14  Fourteen  653 non-null    int64  \n",
      " 15  Approval  653 non-null    int64  \n",
      "dtypes: float64(4), int32(9), int64(3)\n",
      "memory usage: 58.8 KB\n"
     ]
    }
   ],
   "source": [
    "encoded_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Seventh</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Tenth</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>Thirteen</th>\n",
       "      <th>Fourteen</th>\n",
       "      <th>Approval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  First  Second  3  4  5  6  Seventh  8  9  Tenth 11 12  Thirteen  \\\n",
       "0  b  30.83   0.000  u  g  w  v     1.25  t  t      1  f  g     202.0   \n",
       "1  a  58.67   4.460  u  g  q  h     3.04  t  t      6  f  g      43.0   \n",
       "2  a  24.50   0.500  u  g  q  h     1.50  t  f      0  f  g     280.0   \n",
       "3  b  27.83   1.540  u  g  w  v     3.75  t  t      5  t  g     100.0   \n",
       "4  b  20.17   5.625  u  g  w  v     1.71  t  f      0  f  s     120.0   \n",
       "\n",
       "   Fourteen Approval  \n",
       "0         0        +  \n",
       "1       560        +  \n",
       "2       824        +  \n",
       "3         3        +  \n",
       "4         0        +  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Seventh</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Tenth</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>Thirteen</th>\n",
       "      <th>Fourteen</th>\n",
       "      <th>Approval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  First  Second  3  4   5  6  Seventh  8  9  Tenth  11  12  Thirteen  \\\n",
       "0  1  30.83   0.000  1  0  12  7     1.25  1  1      1   0   0     202.0   \n",
       "1  0  58.67   4.460  1  0  10  3     3.04  1  1      6   0   0      43.0   \n",
       "2  0  24.50   0.500  1  0  10  3     1.50  1  0      0   0   0     280.0   \n",
       "3  1  27.83   1.540  1  0  12  7     3.75  1  1      5   1   0     100.0   \n",
       "4  1  20.17   5.625  1  0  12  7     1.71  1  0      0   0   2     120.0   \n",
       "\n",
       "   Fourteen  Approval  \n",
       "0         0         1  \n",
       "1       560         1  \n",
       "2       824         1  \n",
       "3         3         1  \n",
       "4         0         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_data.drop(['Approval'], axis = 'columns')\n",
    "X_scaled = preprocessing.scale(X)\n",
    "y = encoded_data.Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr=Pipeline([('pca1',PCA(n_components=2)),\n",
    "                     ('lr_classifier',LogisticRegression(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_randomforest=Pipeline([('pca3',PCA(n_components=2)),\n",
    "                     ('rf_classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt=Pipeline([('pca2',PCA(n_components=2)),\n",
    "                     ('dt_classifier',DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "best_classifier = 0\n",
    "best_pipeline = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.8244274809160306\n",
      "Decision Tree Test Accuracy: 0.7175572519083969\n",
      "RandomForest Test Accuracy: 0.7709923664122137\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy:Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_test,y_test)>best_accuracy:\n",
    "        best_accuracy=model.score(X_test,y_test)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {        \"penalty\": ['l2'],\n",
    "                 \"C\": np.logspace(0, 4, 10),\n",
    "                 \"solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] solver=newton-cg, penalty=l2, C=1.0 .............................\n",
      "[CV] .............. solver=newton-cg, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=1.0 .............................\n",
      "[CV] .............. solver=newton-cg, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=1.0 .............................\n",
      "[CV] .............. solver=newton-cg, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=1.0 ..................................\n",
      "[CV] ................... solver=saga, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=1.0 ..................................\n",
      "[CV] ................... solver=saga, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=1.0 ..................................\n",
      "[CV] ................... solver=saga, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=1.0 ...................................\n",
      "[CV] .................... solver=sag, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=1.0 ...................................\n",
      "[CV] .................... solver=sag, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=1.0 ...................................\n",
      "[CV] .................... solver=sag, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=1.0 .............................\n",
      "[CV] .............. solver=liblinear, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=1.0 .............................\n",
      "[CV] .............. solver=liblinear, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=1.0 .............................\n",
      "[CV] .............. solver=liblinear, penalty=l2, C=1.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=2.7825594022071245 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=2.7825594022071245 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=2.7825594022071245 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=2.7825594022071245 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=2.7825594022071245 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=2.7825594022071245 ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 40 is smaller than n_iter=50. Running 40 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... solver=saga, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=2.7825594022071245 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=2.7825594022071245 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=2.7825594022071245 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=2.7825594022071245 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=2.7825594022071245 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=2.7825594022071245 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=2.7825594022071245, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=7.742636826811269 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=7.742636826811269 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=7.742636826811269 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=7.742636826811269 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=7.742636826811269 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=7.742636826811269 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=7.742636826811269 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=7.742636826811269 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=7.742636826811269 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=7.742636826811269 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=7.742636826811269 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=7.742636826811269 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=7.742636826811269, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=21.544346900318832 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=21.544346900318832 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=21.544346900318832 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=21.544346900318832 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=21.544346900318832 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=21.544346900318832 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=21.544346900318832 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=21.544346900318832 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=21.544346900318832 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=21.544346900318832 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=21.544346900318832 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=21.544346900318832 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=liblinear, penalty=l2, C=21.544346900318832, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=59.94842503189409 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=59.94842503189409 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=59.94842503189409 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=59.94842503189409 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=59.94842503189409 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=59.94842503189409 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=59.94842503189409 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=59.94842503189409 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=59.94842503189409 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=59.94842503189409 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=59.94842503189409 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=59.94842503189409 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=59.94842503189409, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=166.81005372000593 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=166.81005372000593 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=166.81005372000593 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=166.81005372000593 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=166.81005372000593 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=166.81005372000593 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=166.81005372000593 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=166.81005372000593 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=166.81005372000593 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=166.81005372000593 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=166.81005372000593 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=166.81005372000593 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=166.81005372000593, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=464.15888336127773 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=464.15888336127773 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=newton-cg, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=464.15888336127773 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=464.15888336127773 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=464.15888336127773 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=464.15888336127773 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=464.15888336127773 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=464.15888336127773 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=464.15888336127773 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=464.15888336127773 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=464.15888336127773 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=464.15888336127773 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=464.15888336127773, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=1291.5496650148827 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=1291.5496650148827 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=1291.5496650148827 ..............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=1291.5496650148827 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=1291.5496650148827 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=1291.5496650148827 ...................\n",
      "[CV] .... solver=saga, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=1291.5496650148827 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=1291.5496650148827 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=1291.5496650148827 ....................\n",
      "[CV] ..... solver=sag, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=1291.5496650148827 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=1291.5496650148827 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=1291.5496650148827 ..............\n",
      "[CV]  solver=liblinear, penalty=l2, C=1291.5496650148827, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=3593.813663804626 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=3593.813663804626 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=newton-cg, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=3593.813663804626 ...............\n",
      "[CV]  solver=newton-cg, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=3593.813663804626 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=3593.813663804626 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=3593.813663804626 ....................\n",
      "[CV] ..... solver=saga, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=3593.813663804626 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=3593.813663804626 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=3593.813663804626 .....................\n",
      "[CV] ...... solver=sag, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=3593.813663804626 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=3593.813663804626 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=3593.813663804626 ...............\n",
      "[CV]  solver=liblinear, penalty=l2, C=3593.813663804626, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=10000.0 .........................\n",
      "[CV] .......... solver=newton-cg, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=10000.0 .........................\n",
      "[CV] .......... solver=newton-cg, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, C=10000.0 .........................\n",
      "[CV] .......... solver=newton-cg, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=10000.0 ..............................\n",
      "[CV] ............... solver=saga, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=10000.0 ..............................\n",
      "[CV] ............... solver=saga, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=saga, penalty=l2, C=10000.0 ..............................\n",
      "[CV] ............... solver=saga, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=10000.0 ...............................\n",
      "[CV] ................ solver=sag, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=10000.0 ...............................\n",
      "[CV] ................ solver=sag, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, C=10000.0 ...............................\n",
      "[CV] ................ solver=sag, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=10000.0 .........................\n",
      "[CV] .......... solver=liblinear, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=10000.0 .........................\n",
      "[CV] .......... solver=liblinear, penalty=l2, C=10000.0, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=l2, C=10000.0 .........................\n",
      "[CV] .......... solver=liblinear, penalty=l2, C=10000.0, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "E:\\Data Science\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=50, n_jobs=1,\n",
       "                   param_distributions={'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                                        'penalty': ['l2'],\n",
       "                                        'solver': ['newton-cg', 'saga', 'sag',\n",
       "                                                   'liblinear']},\n",
       "                   random_state=0, verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "lg = LogisticRegression()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "lg_random = RandomizedSearchCV(estimator = lg, param_distributions = grid, n_iter = 50, cv = 3, verbose=2, random_state=0, n_jobs = 1)\n",
    "# Fit the random search model\n",
    "lg_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'newton-cg', 'penalty': 'l2', 'C': 1.0}\n",
      "The mean accuracy of the model is: 0.8931297709923665\n"
     ]
    }
   ],
   "source": [
    "print(lg_random.best_params_)\n",
    "print(\"The mean accuracy of the model is:\", lg_random.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression(random_state = 0)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_result = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = LogisticRegression(random_state = 0, solver = 'newton-cg', penalty = 'l2', C = 1)\n",
    "best_random.fit(X_train, y_train)\n",
    "best_result = best_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931297709923665"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(best_result, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I picked LogisticRegression with such parameters: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 1.0}\n",
    "Accuracy of the model is 89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8702290076335878"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(gamma = 'auto', kernel = 'rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "svc_result = svc.predict(X_test)\n",
    "accuracy_score(svc_result, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression(random_state = 0, solver = 'newton-cg', penalty = 'l2', C = 1)\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = SVC(gamma = 'auto', kernel = 'rbf')\n",
    "estimators.append(('svm', model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8637296037296037\n"
     ]
    }
   ],
   "source": [
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X_scaled, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logistic',\n",
       "                              LogisticRegression(C=1, random_state=0,\n",
       "                                                 solver='newton-cg')),\n",
       "                             ('svm', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_result = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8702290076335878"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ens_result, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_approval(row):\n",
    "    df = pd.concat([data.drop(['Approval'], axis = 'columns'), row])\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    df.loc[:, df.dtypes == np.object] = df.loc[:, df.dtypes == np.object].apply(encoder.fit_transform)\n",
    "    df = preprocessing.scale(df)\n",
    "    scaled_encoded_row = df[-1]\n",
    "    scaled_encoded_row = scaled_encoded_row.reshape(1, -1)\n",
    "    \n",
    "    estimators = []\n",
    "    model1 = LogisticRegression(random_state = 0, solver = 'newton-cg', penalty = 'l2', C = 1)\n",
    "    estimators.append(('logistic', model1))\n",
    "    model2 = SVC(gamma = 'auto', kernel = 'rbf')\n",
    "    estimators.append(('svm', model2))\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators)\n",
    "    ensemble.fit(X_scaled, y)\n",
    "    result = ensemble.predict(scaled_encoded_row)\n",
    "#     return result\n",
    "    if result == 1:\n",
    "        row['Approval'] = '+'\n",
    "        print(row)\n",
    "    else:\n",
    "        row['Approval'] = '-'\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('test_row.txt', delimiter=\",\", header=None, na_values=[\"?\"], names=['0', 'First', 'Second', '3','4', '5', '6', 'Seventh','8', '9', 'Tenth', '11','12', 'Thirteen', 'Fourteen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Seventh</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Tenth</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>Thirteen</th>\n",
       "      <th>Fourteen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>1.5</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  First  Second  3  4  5  6  Seventh  8  9  Tenth 11 12  Thirteen  \\\n",
       "0  b   34.0     5.5  y  p  c  v      1.5  f  f      0  t  g        60   \n",
       "\n",
       "   Fourteen  \n",
       "0         0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  First  Second  3  4  5  6  Seventh  8  9  Tenth 11 12  Thirteen  \\\n",
      "0  b   34.0     5.5  y  p  c  v      1.5  f  f      0  t  g        60   \n",
      "\n",
      "   Fourteen Approval  \n",
      "0         0        -  \n"
     ]
    }
   ],
   "source": [
    "credit_approval(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
